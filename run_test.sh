#!/bin/bash

# Test script to run tokenization test
echo "ğŸ§ª Running Tokenization Test"
echo "=============================="

# Check if uv is available
if ! command -v uv &> /dev/null; then
    echo "âŒ uv is not installed. Please install it first:"
    echo "   curl -LsSf https://astral.sh/uv/install.sh | sh"
    exit 1
fi

# Check if test.html exists
if [ ! -f "test.html" ]; then
    echo "âŒ test.html not found"
    exit 1
fi

# Install dependencies with uv
echo "ğŸ“¦ Installing Python dependencies with uv..."
uv sync

# Run the test
echo "ğŸš€ Running tokenization test..."
uv run python test_tokenizer.py --model gpt2 --input test.html --output output.html

# Check if output was created
if [ -f "output.html" ]; then
    echo "âœ… Test completed successfully!"
    echo "ğŸ“„ Output file: output.html"
    echo "ğŸŒ Open output.html in your browser to see the results"
else
    echo "âŒ Test failed - output.html was not created"
    exit 1
fi
